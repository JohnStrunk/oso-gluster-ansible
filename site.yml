# vim: set ts=2 sw=2 et :
---
########################################
# This file declares the desired configuration of the Gluster cluster(s)
#
# Server organization:
# - A Gluster cluster is contained entirely within a region.
# - Each region may have more than 1 cluster
# - Nodes within a cluster are divided into groups
# - Each group has 3 total servers, each of which is in a different AZ
# - Volumes are constructed from a group of servers (replica=3)
#
# Required tags:
# For this playbook to function properly, the ec2 instances need to have the
# following tags applied to them:
#   gluster-group: <group-id>
#   (e.g., gluster-group=us-east-2-c00-g00)
# One host from each cluster should additionally have a tag:
#   gluster-master: <cluster-id>
#   (e.g., gluster-master=us-east-2-c00)
# This "master" host will be used for peer probe and volume operations


- name: Prepare Gluster TLS CA
  hosts: localhost
  become: false
  roles:
  - prepare-gluster-ca


- name: Install Gluster on servers
  hosts: tag_gluster_server
  become: true
  roles:
  - gluster-server


- name: Install Gluster client everywhere
  hosts: all
  become: true
  roles:
  - gluster-client


- name: Clean up local TLS files
  hosts: localhost
  become: false
  tasks:
  - name: Clean up local temp directory
    file:
      path: "{{ hostvars.localhost.tempdir }}"
      state: absent


- import_playbook: playbooks/gluster-volume.yml
  vars:
    cluster: "{{ groups['tag_gluster_server'] |
                 intersect(groups['us-east-2']) |
                 intersect(groups['tag_cluster_0']) }}"
    volume_name: supervol0
    size: 1T
    device: /dev/xvdb
    master: "{{ cluster | intersect(groups['tag_manager_true']) }}"
    server_group: "{{ cluster | intersect(groups['tag_group_0']) }}"


# Need to add managed reboot sequence here
# Reboot by AZ, ensuring hosts are up & healed before each reboot
# Conditions:
#   when: rhgs_updated.changed == true
